<!DOCTYPE html>
<html lang="en-US" class="scroll-smooth dark">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>

<meta charset="UTF-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>翻译:Understanding the LMAX Disruptor</title>
<meta
  name="description"
  content="翻译前言 知道Disruptor这个代码库，是在Log4j 1.X升级版Log4j2中提到的，那时候就好奇它为何如此高效，关于Disruptor的文章在ifeve.com上已经有很多了，这一篇讲的更简单。
由于个人英文水平有限，更多是意译。
&mdash;&mdash; 我是分割线 &mdash;&mdash;
LMAX Disruptor 是由一家金融交易平台公司LMAX Exchange开源的Java包,它为线程间的通信问题提供了极其优雅，高效的解决方案。
在这篇博文中，我先描述关于传统排队系统在跨线程之间的内存共享问题，然后试图弄清楚LAMX Disruptor 在该问题上有什么特别方案，他们是如何做到的。
LMAX Disuptor 的解决方案比ArrayBlockingQueue和LinkedBlockingQueue要快。 Mechanical sympathy让你成为更好的开发人员。(更好地理解底层硬件) 在线程中共享内存很容易引发问题，你需要小心对待。 CPU缓存比主存更快，但是不懂得他们是如何工作的(行缓存，等等)反而会严重影响性能。 内存伪共享 举个例子，我们需要对一个计数循环递增到MAX:"
/>
<link rel="canonical" href="http://localhost:1313/post/2019-04-19-understanding-the-lmax-disruptor/" />
<link rel="robots" href="/robots.txt" />

<link rel="icon" type="image/x-icon" href="/icons/favicon.ico" />



<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });</script>

<link rel="stylesheet" href="http://localhost:1313/css/app.css" /></head>

  <body class="max-w-screen-md mx-auto">
    <div class="header">
      <header class="flex flex-col sm:flex-row items-center gap-5 sm:gap-10 pt-16 py-12">
   


<div class="flex-none w-20 h-20 rounded-full overflow-hidden">
  <a href="http://localhost:1313/">
    <img
      srcset="/img/profile-picture_hucbf2afd9e62dc6021c155b0731b41164_625734_80x80_fill_q90_box_smart1.jpg 80w"
      src="/img/profile-picture.jpg"
      width="1080"
      height="1080"
      alt="Enhanced Lowkey Hugo"
    />
  </a>
</div>

  
  <div class="flex flex-col gap-5">
    <a href="http://localhost:1313/">
  <h1 id="site-title">Enhanced Lowkey Hugo</h1>
</a>
 
    <nav>
  <ul>
     
    
    <li>
      <a href="/" class="">
        Home
      </a>
    </li>
    
    <li>
      <a href="/about" class="">
        About me
      </a>
    </li>
    
    <li>
      <a href="/categories" class="">
        Categories
      </a>
    </li>
    
    <li>
      <a href="/tags" class="">
        Tags
      </a>
    </li>
    
    <li>
      <a href="https://ko-fi.com/nixentric" class="">
        Donate
      </a>
    </li>
    
    <li>
      <a href="/about/" class="">
        About
      </a>
    </li>
    
  </ul>
</nav>

  </div>
</header>

      <button class="toggle-theme" aria-label="Toggle Theme" title="Toggle Theme" onclick="toggleTheme()">
  <span class="theme-icon light"> <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor">
    <path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386l-1.591 1.591M21 12h-2.25m-.386 6.364l-1.591-1.591M12 18.75V21m-4.773-4.227l-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 11-7.5 0 3.75 3.75 0 017.5 0z" />
</svg> </span>
  <span class="theme-icon dark"> <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor">
    <path stroke-linecap="round" stroke-linejoin="round" d="M21.752 15.002A9.718 9.718 0 0118 15.75c-5.385 0-9.75-4.365-9.75-9.75 0-1.33.266-2.597.748-3.752A9.753 9.753 0 003 11.25C3 16.635 7.365 21 12.75 21a9.753 9.753 0 009.002-5.998z" />
</svg> </span>
</button>

<script>
  document.addEventListener('DOMContentLoaded', function () {
    const theme = localStorage.getItem('theme');

    if (!theme || theme === 'light') {
      setTheme('light');
    } else {
      setTheme(theme);
    }
  });

  function setTheme(theme) {
    const html = document.querySelector('html');
    localStorage.setItem('theme', theme);

    if (theme === 'light') {
      if (html.classList.contains('dark')) {
        document.querySelector('html').classList.remove('dark');
      }

      document.querySelector('.theme-icon.light').style.display = 'none';
      document.querySelector('.theme-icon.dark').style.display = 'block';
    } else {
      if (!html.classList.contains('dark')) {
        document.querySelector('html').classList.add('dark');
      }

      document.querySelector('.theme-icon.dark').style.display = 'none';
      document.querySelector('.theme-icon.light').style.display = 'block';
    }
  }

  function toggleTheme() {
    const theme = localStorage.getItem('theme');

    if (theme === 'light') {
      setTheme('dark');
    } else {
      setTheme('light');
    }
  }
</script>
    </div>
  
    <main id="content">

<article class="flex flex-col gap-10">
  <header class="flex flex-col gap-2">
    <h2 class="title-large">翻译:Understanding the LMAX Disruptor</h2>

    <div class="meta">
      
      <time datetime="2019-04-19 21:24:47 &#43;0000 UTC" title='Fri, Apr 19, 2019, 9:24 PM UTC'>
        19/04/2019 - Estimated reading time: 4 minutes
      </time>

       
       — 
        
          <a class="categories" href="/categories/software-design/" alt="Software Design">
            Software Design
          </a>
         
      
    </div>
  </header>

  

  <section><h3 id="翻译前言">翻译前言</h3>
<p>知道Disruptor这个代码库，是在Log4j 1.X升级版Log4j2中提到的，那时候就好奇它为何如此高效，关于Disruptor的文章在<a href="http://ifeve.com/disruptor/">ifeve.com</a>上已经有很多了，这一篇讲的更简单。</p>
<p>由于个人英文水平有限，更多是意译。</p>
<p>&mdash;&mdash; 我是分割线 &mdash;&mdash;</p>
<p><a href="https://github.com/LMAX-Exchange/disruptor">LMAX Disruptor</a> 是由一家金融交易平台公司<a href="https://www.lmax.com/">LMAX Exchange</a>开源的Java包,它为线程间的通信问题提供了极其优雅，高效的解决方案。</p>
<p>在这篇博文中，我先描述关于传统排队系统在跨线程之间的内存共享问题，然后试图弄清楚LAMX Disruptor 在该问题上有什么特别方案，他们是如何做到的。</p>
<p><img src="http://blog.xiebiao.com/images/2019-04-19-understanding-the-lmax-disruptor/1_faUySbv7t8aAFm0X1zTMwg.png" alt="understanding-the-lmax-disruptor" title=""></p>
<ul>
<li>LMAX Disuptor 的解决方案比<code>ArrayBlockingQueue</code>和<code>LinkedBlockingQueue</code>要快。</li>
<li><a href="http://mechanical-sympathy.blogspot.com/">Mechanical sympathy</a>让你成为更好的开发人员。(更好地理解底层硬件)</li>
<li>在线程中共享内存很容易引发问题，你需要小心对待。</li>
<li>CPU缓存比主存更快，但是不懂得他们是如何工作的(行缓存，等等)反而会严重影响性能。</li>
</ul>
<h3 id="内存伪共享">内存伪共享</h3>
<p>举个例子，我们需要对一个计数循环递增到<code>MAX</code>:</p>
<pre tabindex="0"><code>public void simple() {
  int counter = 0;
  for (int i = 0; i &lt; MAX; i++) {
    counter++;
  }

  System.out.println(&#34;counter=&#34; + counter);
}
</code></pre><p>因为<code>MAX</code>值可能会很大，为了关注性能，我们决定在多核处理器上来跑这个程序，将这个任务分到两个独立的线程上执行，像这样:</p>
<pre tabindex="0"><code>public void multi() throws Exception {
  // First thread
  final Thread t1 =
      new Thread(() -&gt; {
        for (int i = 0; i &lt; MAX / 2; i++) {
          sharedCounter++;
        }
      });

  // Second thread
  final Thread t2 =
      new Thread(() -&gt; {
        for (int i = 0; i &lt; MAX / 2; i++) {
          sharedCounter++;
        }
      });

  // Start threads
  t1.start();
  t2.start();

  // Wait threads
  t1.join();
  t2.join();

  System.out.println(&#34;counter=&#34; + sharedCounter);
}
</code></pre><p>可是这个实现有两个问题。</p>
<p>首先,多次执行将<code>MAX</code>累加到1百万，很显然这和我们期望输出结果<code>counter=1000000</code>有点不一样。(这里完全是个人为了句子更符合中文语景)</p>
<pre tabindex="0"><code>counter=522388
counter=733903
counter=532331
</code></pre><p>由于变量 <code>sharedCounter</code>上的条件竞争，执行结果出现了不确定性。</p>
<p>当线程执行依赖执行顺序和时间，那么就会产生竞态。发生这种情况，是因为<code>sharedCounter</code>在没有被保护的情况下，同时被两个线程修改。</p>
<p>其次，至于性能，即使<code>MAX</code>被设置成一个很大的值足以忽略两个线程的管理，这个结果依然要慢3倍(文章这里应该是在和单线程下执行结果做比较)。这是什么原因？</p>
<p>由于两个线程属于CPU计算密集型，操作系统很有可能会将他们分配到不同的CPU内核上，另外，我们有理由相信
两个运行在不同内核上的线程可以自由共享内存，然而，我们忘了CPU缓存的概念:</p>
<p><img src="http://blog.xiebiao.com/images/2019-04-19-understanding-the-lmax-disruptor/1_I_7Ju4oDPgTYO6Y-uPqdQg.png" alt="understanding-the-lmax-disruptor" title="Memory layers"></p>
<p>为了避免每次都访问主存中查询内存地址，CPU会将数据保存在自己的缓存中: 本地一级缓存，二级缓存，和共享三级缓存。</p>
<p><a href="https://software.intel.com/sites/products/collateral/hpc/vtune/performance_analysis_guide.pdf">Core i7 Xeon 5500</a>的特性:</p>
<pre tabindex="0"><code>Memory                   Latency      
L1 CACHE hit         ~4 cycles (~1.2 ns) | 
L2 CACHE hit         ~10 cycles (~3.0 ns)   |   
L3 CACHE hit          (~60.0 ns) |   
</code></pre><p>当处理器想访问一个内存地址，首先会在一级缓存中查找，如果不存在，再从二级缓存中查找，同样如果不存在就到三级缓存中查找，
直到最后到主存中查找。(主存比一级缓存慢60倍，一级缓存和二级缓存是CPU内核独占，三级缓存是所有CPU内核共享)</p>
<p>在我们的例子中，因为<code>sharedCounter</code> 同时被两个不同的CPU内核更新，变量在两个一级缓存中来回同步，大幅度降低了执行速度。</p>
<p>最后，这里有另外一个关于CPU缓存的重要概念: CPU缓存行(CPU缓存的组织形式)</p>
<p>一个缓存行是由2的N次方的连续字节组成，常见的是64字节，它由一个非链式的HashMap维护，每个内存地址都影射到指定的缓存行上。</p>
<p>举例,如果两个变量<code>x</code>和<code>y</code> 被两个不同的CPU内核的线程顺序访问，第一个线程修改<code>x</code>，另外一个在很短时间内修改了<code>y</code>(原文为啥要精确到纳秒来阐述?)。
假设两个变量都在同一个缓存行，即使程序只关心变量<code>y</code>而不是<code>x</code>,第二线程依然会看到整个缓存行被设置成了<code>无效</code>，从而导致第二个内核需要重新获得一份缓存行的拷贝(他们可能在2级或者3级缓存，甚至在主存中)。</p>
<p>这个问题就是所谓的<code>伪共享</code>,它是影响性能的重要因素(尽管CPU最终会保证执行结果的确定性)。</p>
<h3 id="并发执行">并发执行</h3>
<p>代码并发执行首先要确保<code>相互排斥</code>,这意味着多线程访问相同的资源需要互相协作。</p>
<p>此外，当发生修改，必须对另外的线程可见，这叫着<code>修改可见性</code></p>
<p>这是并发的两个主要概念。</p>
<h3 id="互相排斥">互相排斥</h3>
<p><code>锁</code>是实现排斥的一种可能解决方案，但是他们在竞争中公平仲裁显得非常昂贵。操作系统在线程等待锁直到释放之前将其挂起，从而形成上下文
切换。</p>
<p>而且，在上下文切换的过程中(当操作系统释放控制，决定去执行其他任务也一样)，执行上下文可能会丢失之前的缓存和指令。</p>
<p>为了理解其中的影响，我们看看在一个64位计数上循环执行递增500万次:</p>
<pre tabindex="0"><code>Test case                            Execution time
Single thread                             300ms
Single thread with lock             10 000 ms
Two thread with lock                 224 000ms
</code></pre><p><code>锁</code>的另外一种替代方案就是 <code>CAS</code>(比较后交换)操作，<code>CAS</code>操作是一个机器指令，它保证操作的原子性(要么全部成功，要么都不成功)。</p>
<p>简而言之，只有传入期望参数与原来值相等时，才会将变量更新，否则让线程继续重试<code>CAS</code>操作。</p>
<pre tabindex="0"><code>   public final int getAndSet(int newValue) {
        for (;;) {
            int current = get();//当前线程获取变量原来的值
            //当current与原来的值相等时，才将变量更新为newValue,因为get到的current，
            //可能已经被另外的线程更新了。
            if (compareAndSet(current, newValue))
                return current;
        }
    }
</code></pre><p>在Java中，<code>Atomic*</code> 类，比如<code>AtomicInteger</code> 都是基于这种操作。</p>
<p>我们比较一下性能:</p>
<pre tabindex="0"><code>Test case                                      Execution time
Single thread with CAS                           5 700 ms
Two threads with CAS                             30 000 ms
</code></pre><p>最后不能不提，如果临界区(被保护的部分)不是单个原子操作，需要多个<code>CAS</code>操作组合，那将会是更复杂处理方式。</p>
<h3 id="修改可见性">修改可见性</h3>
<p>修改可见性可以通过<code>内存屏障</code>来做到。(也叫内存栅栏)</p>
<blockquote>
<p>A memory barrier causes a CPU to enforce an ordering constraint on memory operations issued before and after the barrier instruction.</p>
</blockquote>
<blockquote>
<p>Source: Wikipedia</p>
</blockquote>
<blockquote>
<p>内存屏障会引起CPU在屏障前后对内存操作指令进行重排。</p>
</blockquote>
<p>我们为什么需要这种机制？大部分现代CPU为了达到最佳性能最终可能会乱序执行。</p>
<p>回到我们第一个例子:</p>
<pre tabindex="0"><code>public void simple() {
  int counter = 0;
  for (int i = 0; i &lt; MAX; i++) {
    counter++;
  }
  System.out.println(&#34;counter=&#34; + counter);
}
</code></pre><p>这个例子，不管在循环体内<code>counter</code>是否被更新，为了执行性能CPU都会进行<code>指令重排</code>。</p>
<p>重排在单线程执行中不会有任何问题，但在并发执行上下文中可能会变得不可预知。</p>
<p>这就是<code>内存屏障</code>目的:</p>
<ul>
<li>确保多核CPU情况下，临界区被所有指令有序访问。</li>
<li>让内存在底层缓存间保持可见。</li>
</ul>
<p><code>内存屏障</code>被分为以下几种类型:(以下内容和原文不太一致)</p>
<blockquote>
<ul>
<li>LoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。</li>
<li>StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。</li>
<li>LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。</li>
<li>StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的。 在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能。</li>
</ul>
</blockquote>
<p><img src="http://blog.xiebiao.com/images/2019-04-19-understanding-the-lmax-disruptor/1_fPGrtZi8xjULvcvoG4jbRw.jpeg" alt="understanding-the-lmax-disruptor" title=" "></p>
<p>在Java中，使用<code>volatile</code>修饰符来插入一个写屏障指令在我们写之后，在读之前插入一个读屏障，同时<code>final</code>修饰的类
在其构造完成后插入一个写屏障来使其可见。</p>
<p>可以通过<code>Unsafe</code>包来访问这些指令。</p>
<p>我们修改一下之前的多线程实现，在访问<code>sharedCounter</code>之前插入一个读屏障，在期后面插入一个写屏障:</p>
<pre tabindex="0"><code>public void barrier() throws Exception {
  // First thread
  final Thread t1 =
      new Thread(() -&gt; {
        for (int i = 0; i &lt; MAX / 2; i++) {
          getUnsafe().loadFence(); // Read barrier
          sharedCounter++;
          getUnsafe().storeFence(); // Store barrier
        }
      });

  // Second thread
  final Thread t2 =
      new Thread(() -&gt; {
        for (int i = 0; i &lt; MAX / 2; i++) {
          getUnsafe().loadFence(); // Read barrier
          sharedCounter++;
          getUnsafe().storeFence(); // Store barrier
        }
      });

  // Start threads
  t1.start();
  t2.start();

  // Wait threads
  t1.join();
  t2.join();

  System.out.println(&#34;counter=&#34; + sharedCounter);
}
</code></pre><p>我们再次运行这个实现 直到<code>MAX</code> 到1百万，我们依然期望得到输出  <code>counter = 1000000</code>:</p>
<pre tabindex="0"><code>-- First multi-threaded implementation without a memory barrier
counter=522388
counter=733903
counter=532331
-- New implementation with memory barriers
counter=999890
counter=999868
counter=999770
</code></pre><p>像我们看到的那样，由于内存屏障的介入，结果已经非常接近我们的预期了，然而，即使内存屏障也不足以阻止非原子操作的条件竞争。</p>
<h3 id="传统队列">传统队列</h3>
<p><img src="http://blog.xiebiao.com/images/2019-04-19-understanding-the-lmax-disruptor/1_pX-zOhchRgU7jJKTVtW9dw.jpeg" alt="understanding-the-lmax-disruptor" title=" "></p>
<p>线程间内存共享另外一个选择就是消息传递: 通过通讯来共享内存。</p>
<p>那意味着我们需要一些东西来处理线程间的通讯，在Java中，一种选择就是使用传统的<code>LinkedBlockingQueue</code>或者<code>ArrayBlockingQueue</code>。</p>
<p>即使队列能确保互斥和修改可见性但依然不能解决并发问题。</p>
<p>我们看一下 <code>ArrayBlockingQueue</code> 的 <code>put</code>方法:</p>
<pre tabindex="0"><code>/** Main lock guarding all access */
final ReentrantLock lock;

public void put(E e) throws InterruptedException {
    checkNotNull(e);
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly(); // Lock accesses
    try {
        while (count == items.length)
            notFull.await();
        enqueue(e); // See method below
    } finally {
        lock.unlock(); // Unlock
    }
}

private void enqueue(E x) {
    final Object[] items = this.items;
    items[putIndex] = x;
    if (++putIndex == items.length)
        putIndex = 0;
    count++;
    notEmpty.signal(); // Send signal to indicate a change
}
</code></pre><p>在一个锁操作中，当一个元素被添加时会给等待线程发送一个信号。</p>
<p>LMAX 小组觉得有趣的是，队列在满载和为空的情况下总是处于关闭状态。(当队列满了的时候，生产者无法再向队列写入，处于等待状态，当
队列为空时，消费者无法从队列中获取，处于等待状态)</p>
<p>如果队列处于满载而无法写入，结果生产者之间出现竞争，以至于导致上下文切换，缓存数据和指令丢失。</p>
<p>而且，传统的队列系统，生产者操作队头的同时消费者操作队尾。如果队列为空，很可能队头，队尾，以及队列的容量都在同一个<code>缓存行</code>中，这将导致上面说的伪共享。</p>
<h3 id="lmax-disruptor">LMAX Disruptor</h3>
<p><img src="http://blog.xiebiao.com/images/2019-04-19-understanding-the-lmax-disruptor/1_q5N4j_PrALLLpZLEU3c5FA.jpeg" alt="understanding-the-lmax-disruptor" title=" "></p>
<p>LMAX Disruptor的缔造者发明的<a href="https://www.infoq.com/presentations/mechanical-sympathy">Mechanical Sympathy</a>也非常著名，
简而言之，开发人员在设计算法，数据结构时要懂得底层硬件。基于这个哲学，该团队才创造这个伟大的代码库。</p>
<blockquote>
<p>Disruptor 显著的降低了写竞争，更低的并发负载，缓存更加友好，实现了高吞吐量，低延迟。</p>
</blockquote>
<blockquote>
<p>来源:<a href="https://lmax-exchange.github.io/disruptor/files/Disruptor-1.0.pdf">Disruptor technical paper</a></p>
</blockquote>
<p>我们分析一下原因:</p>
<p>首先,Disruptor基于 <a href="https://en.wikipedia.org/wiki/Circular_buffer">ring buffer structure</a>, 它就像一个个固定长度的缓存区首尾相连。</p>
<p><img src="http://blog.xiebiao.com/images/2019-04-19-understanding-the-lmax-disruptor/1_soxodeCvj-FY8vrl_WY6kA.png" alt="understanding-the-lmax-disruptor" title="Ring buffer structure"></p>
<p>初始化时，分配指定的内存大小(必须是2的N次方)，以及一个事件初始化工厂。</p>
<pre tabindex="0"><code>Disruptor&lt;MyEvent&gt; disruptor =
  new Disruptor&lt;&gt;(
      () -&gt; new MyEvent(), // Factory for events
      ringBufferSize, // Buffer size
      threadFactory, 
      producerType, 
      waitStrategy);
</code></pre><p>这里启动的时候，我们分配了一个<code>ringBufferSize</code>大小的 <code>MyEvent</code>类实例。</p>
<p>同时我们提供了一个工厂来创建事件处理器线程，以及一个降低订阅者的策略。我们稍微在后面再讨论生产者。</p>
<p>事件实例在Disruptor中将会被重复利用，相比传统的队列会被垃圾回收器处理，事件会存活更长时间。</p>
<p>在内部， ring buffer支持对象数组，据创造者说这是一个很好的选择。在硬件层级，数组有一个可预知的访问模式，
元素可以预加载，所以事件处理器不用频繁的回到主存中加载下一个元素。这样，我们就可以高效地遍历，而不像队列
那样通过链表的方式访问。</p>
<p>可以像这样配置一个消费者:</p>
<pre tabindex="0"><code>disruptor.handleEventsWith(
        (event, sequence, endOfBatch) -&gt; System.out.println(event));
</code></pre><p>对<code>handleEventsWith()</code>我们提供lambda表达式, lambda有三个输入:</p>
<ul>
<li>事件本身</li>
<li>一个序列号</li>
<li>是否批量处理</li>
</ul>
<p>多生产者的情况下，他们都会收到每个事件，如果我们像分开加载，我们可以实现基于序列号的分片策略，像这样:</p>
<pre tabindex="0"><code>disruptor.handleEventsWith(
    (event, sequence, endOfBatch) -&gt; {
      if (sequence % 2 == 0) {
        System.out.println(&#34;Consumer 1: &#34; + event.getPayload());
      }
    },
    (event, sequence, endOfBatch) -&gt; {
      if (sequence % 2 == 1) {
        System.out.println(&#34;Consumer 2: &#34; + event.getPayload());
      }
    }
);
</code></pre><p>然后我们可以启动 Disruptor，返回一个<code>RingBuffer</code>实例。</p>
<pre tabindex="0"><code>RingBuffer&lt;MyEvent&gt; ringBuffer = disruptor.start();
</code></pre><p>当<code>Disruptor</code>实例被启动，我们就可以通过下面这样发布事件:</p>
<pre tabindex="0"><code>final long sequence = ringBuffer.next(); // Ask the ring buffer the next sequence
final MyEvent event = ringBuffer.get(sequence); // Get the event instance
event.setPayload(&#34;Hello, World!&#34;); // Business logic
ringBuffer.publish(sequence); // Publish an event
</code></pre><p>序列号表示事件在ring buffer数据结构中的位置。</p>
<p>当我们创建<code>Disruptor</code>实例，我们同时要传入一个<code>producerType</code>变量(它是<code>ProducerType.SINGLE</code>或<code>ProducerType.MULTI</code>之一)。告诉<code>Disruptor</code>我们是否有单个还是多个生产者。</p>
<p>在单个生产者的情况下，<code>ringBuffer.next()</code>完全是一个无锁操作。另外一方面，如果我们有多个生产者，这个方法通过<code>CAS</code>操作从ring buffer中获取下一个序列号。</p>
<p>序列号通过内存补全的方式确保在同一个缓存行中不包含其他数据:</p>
<pre tabindex="0"><code>class LhsPadding {
    protected long p1, p2, p3, p4, p5, p6, p7;
}

class Value extends LhsPadding {
    protected volatile long value;
}

class RhsPadding extends Value {
    protected long p9, p10, p11, p12, p13, p14, p15;
}
</code></pre><p>而且，通过创建一个内存屏障，确保所有缓存得到发布事件的更新。在ring buffer中添加一个事件完全不需要锁，从而性能得到了大大提升。</p>
<p>最后一点需要提到的，我们说ring buffer底层是一个数组，那意味着，开发人员阻止了同缓存行中的可能出现的伪共享问题。</p>
<p>我们看看Disruptor开发小组对Disruptor与<code>ArrayBlockingQueue</code>比较。</p>
<p>测试中的吞吐性能ops/sec(P表示生产者，C表示消费者)</p>
<p><em><strong>性能测试数据对比这里就不翻译了</strong></em></p>
<blockquote>
<p>原文地址: <a href="https://itnext.io/understanding-the-lmax-disruptor-caaaa2721496">https://itnext.io/understanding-the-lmax-disruptor-caaaa2721496</a></p>
</blockquote>
<p>&mdash;&mdash; 我是分割线 &mdash;&mdash;</p>
<h3 id="扩展阅读">扩展阅读</h3>
<ul>
<li>
<p><a href="https://lmax-exchange.github.io/disruptor/disruptor.html">Disruptor介绍</a></p>
</li>
<li>
<p><a href="https://mirrors.edge.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html"><em>Is Parallel Programming Hard, And, If So, What Can You Do About It?</em></a></p>
</li>
<li>
<p><a href="http://blog.xiebiao.com/post/2020-08-19-locks-on-multicore/"><em>计算机多核平台上的锁(一)</em></a></p>
</li>
</ul>
<h3 id="翻译后记">翻译后记</h3>
<h4 id="关于翻译">关于翻译</h4>
<p>很早以前发现使用英译中工具查单词，有个严重的误区，比如<code>ruin</code>这个单词，百度翻译/有道翻译/google翻译基本都是告诉你中文意思为：<code>毁灭；使破产</code>。
但是用<a href="https://www.ldoceonline.com/dictionary/ruin">朗文翻译</a>得到的英文解释为: <code>to spoil or destroy something completely</code>,这个解释里面明显有个<code>程度</code>在里面，
如果翻译成<code>毁灭</code>就显得生硬，影响理解。</p>
</section>

  
    
  

    
  


  <footer>
    
      <div class="pb-14 taxonomy-list tags-list">
      
        <a href="/tags/disruptor/" alt="Disruptor">
          Disruptor
        </a>
      
        <a href="/tags/advanced-data-structure/" alt="Advanced Data Structure">
          Advanced Data Structure
        </a>
      
        <a href="/tags/translate/" alt="Translate">
          Translate
        </a>
      
      </div>
    
  </footer>
</article>


    </main><footer class="pt-5 pb-10 grid gap-3 sm:grid-cols-2">
    <div class="text-xs font-semibold text-gray-500 order-2 sm:order-1">
  © 2024 —
  <a href="http://localhost:1313/">Enhanced Lowkey Hugo</a> 
  <span class="font-normal">with</span>
  <a
    href="https://github.com/nixentric/Lowkey-Hugo-Theme"
    target="_blank"
    rel="noopener noreferrer"
  >
    Lowkey
  </a>
</div>

    <div class="order-1 sm:order-2">
  <ul class="flex sm:justify-end gap-5">
    
    
    <li>    
      <a href="#" target="_blank" rel="noopener noreferrer">Twitter</a>
    </li>
    
    <li>    
      <a href="#" target="_blank" rel="noopener noreferrer">Instagram</a>
    </li>
    
    <li>    
      <a href="#" target="_blank" rel="noopener noreferrer">GitHub</a>
    </li>
    
    
  </ul>
</div>

</footer></body>
</html>
